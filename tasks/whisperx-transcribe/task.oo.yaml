inputs_def:
  # Basic Input
  - handle: audio_file
    description: "%audio-file-to-transcribe-supports-mp3-wav-m4a-flac-etc%"
    json_schema:
      type: string
      ui:widget: file
    nullable: false

  # Basic Settings
  - group: Basic Settings
    collapsed: false

  - handle: model_size
    description: "%whisper-model-size-larger-more-accurate-but-slower%"
    json_schema:
      type: string
      enum:
        - tiny
        - base
        - small
        - medium
        - large-v2
        - large-v3
    value: medium
    nullable: false

  - handle: language
    description: "Language for transcription (auto-detect if not specified)"
    json_schema:
      type: string
      enum:
        - auto
        - zh
        - en
        - ja
        - ko
        - es
        - fr
        - de
        - ru
        - ar
        - pt
        - it
        - nl
        - pl
        - tr
        - vi
        - id
        - th
        - hi
    value: auto
    nullable: false

  - handle: enable_alignment
    description: "%enable-word-level-timestamp-alignment-more-accurate-timestamps%"
    json_schema:
      type: boolean
    value: true
    nullable: false

  # Speaker Diarization
  - group: Speaker Diarization
    collapsed: true

  - handle: enable_diarization
    description: "%enable-speaker-diarization-requires-huggingface-token%"
    json_schema:
      type: boolean
    value: false
    nullable: false

  - handle: hf_token
    description: "%huggingface-token-required-for-diarization-feature%"
    json_schema:
      contentMediaType: oomol/secret
      type: string
    value: ${{OO_SECRET:HuggingFace,HuggingFace,HF_TOKEN}}
    nullable: true

  # Performance Settings
  - group: Performance Settings
    collapsed: true

  - handle: batch_size
    description: "%batch-size-for-inference-higher-faster-but-more-gpu-memory%"
    json_schema:
      type: integer
      minimum: 1
      maximum: 64
    value: 16
    nullable: false

  - handle: compute_type
    description: "%computation-precision-float16-for-gpu-int8-for-cpu%"
    json_schema:
      type: string
      enum:
        - float16
        - int8
        - float32
    value: float16
    nullable: false

  # Advanced Transcription Settings
  - group: Advanced Transcription Settings
    collapsed: true

  - handle: beam_size
    description: "Beam size for beam search (5 recommended, larger = more accurate
      but slower)"
    json_schema:
      type: integer
      minimum: 1
      maximum: 10
    value: 5
    nullable: false

  - handle: best_of
    description: "Number of candidates when sampling with non-zero temperature"
    json_schema:
      type: integer
      minimum: 1
      maximum: 10
    value: 5
    nullable: false

  - handle: temperature
    description: "Sampling temperature (0 = deterministic, higher = more random)"
    json_schema:
      type: number
      minimum: 0
      maximum: 1
    value: 0
    nullable: false

  - handle: patience
    description: "Patience for beam search (higher = explore more hypotheses)"
    json_schema:
      type: number
      minimum: 0
      maximum: 2
    value: 1
    nullable: false

  - handle: length_penalty
    description: "Length penalty for beam search (>1 prefers longer, <1 prefers shorter)"
    json_schema:
      type: number
      minimum: 0
      maximum: 2
    value: 1
    nullable: false

  - handle: condition_on_previous_text
    description: "Use previous text as context for next segment (improves coherence)"
    json_schema:
      type: boolean
    value: true
    nullable: false

  - handle: initial_prompt
    description: "Optional initial prompt to guide transcription style"
    json_schema:
      type: string
      ui:widget: text
    value:
    nullable: true

  # VAD (Voice Activity Detection) Settings
  - group: VAD Settings
    collapsed: false

  - handle: vad_filter
    description: "Enable VAD filter to reduce hallucinations and improve accuracy"
    json_schema:
      type: boolean
    value: true
    nullable: false

  - handle: vad_onset
    description: "VAD onset threshold (0-1, LOWER = more sensitive, 0.2 for max capture)"
    json_schema:
      type: number
      minimum: 0
      maximum: 1
    value: 0.1
    nullable: false

  - handle: vad_offset
    description: "VAD offset threshold (0-1, LOWER = keeps more audio, 0.2 recommended)"
    json_schema:
      type: number
      minimum: 0
      maximum: 1
    value: 0.1
    nullable: false

  - handle: min_speech_duration
    description: "Min speech duration in seconds (WhisperX fixed at 0.1s, this param
      is ignored)"
    json_schema:
      type: number
      minimum: 0
      maximum: 2
    value: 0.1
    nullable: false

  - handle: min_silence_duration
    description: "Min silence duration in seconds (WhisperX fixed at 0.1s, this
      param is ignored)"
    json_schema:
      type: number
      minimum: 0
      maximum: 2
    value: 0.1
    nullable: false

  - handle: chunk_size
    description: "Audio chunk size in seconds (default 30, smaller = more precise)"
    json_schema:
      type: integer
      minimum: 10
      maximum: 60
    value: 30
    nullable: false

outputs_def:
  - handle: transcript_text
    description: "Full transcription text"
    json_schema:
      type: string

  - handle: segments
    description: "Transcription segments with timestamps and speaker info"
    json_schema:
      type: string
      contentMediaType: application/json

  - handle: output_file
    description: "Path to the output JSON file"
    json_schema:
      type: string

executor:
  name: python
  options:
    entry: __init__.py
    spawn: false

title: "%whisperx-transcribe%"
icon: ":carbon:audio-console:"
description: "%fast-automatic-speech-recognition-with-word-level-timestamps-and%"
ui:
  default_width: 593.3949020481755
